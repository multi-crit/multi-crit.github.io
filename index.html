<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following">
  <meta name="keywords" content="Benchmarks, Multimodal Judges, Criteria-Following">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <!-- <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div> -->
</nav>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
    <!-- <div class="container"> -->
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">
              <img src="./static/images/favicon.svg" 
       alt="icon" 
       style="width: 40px; vertical-align: middle; margin-right: 8px;">
            Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following
          </h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://tyxiong23.github.io/">Tianyi Xiong</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://www.ellenyige.com/">Yi Ge</a><sup>1*</sup>,</span>
            <span class="author-block">
              <a href="https://scholar.google.com/citations?user=M4ojgE4AAAAJ">Ming Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Zuolong Zhang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://itspranavk.github.io/">Pranav Kulkarni</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kaishen-wang.github.io/">Kaishen Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="">Qi He</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zzylol.github.io/">Zeying Zhu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://dawnliu35.github.io/">Chenxi Liu</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://rayruibochen.github.io/">Ruibo Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://kidzheng.github.io/">Tong Zheng</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://chenyanshuo.com/">Yanshuo Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://si0wang.github.io/">Xiyao Wang</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://zrrskywalker.github.io/">Renrui Zhang</a>,</span>
            <span class="author-block">
              <a href="https://wenhuchen.github.io/">Wenhu Chen</a><sup>2</sup>,</span>
            <span class="author-block">
              <a href="https://www.cs.umd.edu/~heng/">Heng Huang</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of Maryland, College Park,</span>
            <span class="author-block"><sup>2</sup>University of Waterloo</span>
          </div>
          <div class="is-size-6 publication-authors">
            <span class="author-block"><sup>*</sup>Core Contributors</span>
          </div>


          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <!-- <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span> -->
              <span class="link-block">
                <a href=""
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
              <!-- Video Link. -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/tyxiong23/Multi-Crit"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span>
              <!-- Dataset Link. -->
              <span class="link-block">
                <a href="https://huggingface.co/datasets/txiong23/multi-crit"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <!-- <i class="far fa-images"></i> -->
                      <p style="font-size:18px">ðŸ¤—</p>
                  </span>
                  <span>Dataset</span>
                  </a>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="./static/videos/teaser.mp4"
                type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        <span class="dnerf">Multi-Crit</span> turns selfie videos from your phone into
        free-viewpoint
        portraits.
      </h2>
    </div>
  </div>
</section> -->





<section class="section">
  <div class="container">
    <!-- Abstract. -->

    
    <!--/ Abstract. -->

      <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large multimodal models (LMMs) are increasingly adopted as judges in multimodal evaluation systems due to their strong instruction following and consistency with human preferences. However, their ability to follow diverse, fine-grained evaluation criteria remains underexplored.

          </p>
          <p>
            We develop Multi-Crit, a benchmark for <b>evaluating multimodal judges on their capacity to follow pluralistic criteria</b> and produce <b>reliable criterion-level judgments</b>. Covering both open-ended generation and verifiable reasoning tasks, Multi-Crit is built through a rigorous data curation pipeline that gathers challenging response pairs with <b>multi-criterion human annotations</b>. It further introduces <b>three novel metrics for systematically assessing pluralistic adherence, criterion-switching flexibility, and the ability to recognize criterion-level preference conflicts</b>.
          </p>
          <p>
            Comprehensive analysis of 25 LMMs reveals that 1) <b>proprietary models still struggle to maintain consistent adherence to pluralistic criteria</b>â€”especially in open-ended evaluation; 2) <b>open-source models lag further behind</b> in flexibly following diverse criteria; and 3) critic fine-tuning with holistic judgment signals enhances visual grounding but fails to generalize to pluralistic criterion-level judgment.
            Additional analyses on reasoning fine-tuning, test-time scaling, and boundary consistency between open-source and proprietary models further probe the limits of current multimodal judges.
            As a pioneering study, Multi-Crit lays the foundation for building reliable and steerable multimodal AI evaluation.
          </p>
        </div>
      </div>
      
    </div>

    <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths">
        <div class="content">
        <img id="teaser"
               src="./static/images/01_teaser.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover; margin-top: 50px;" />
        </div>
        <p> 
          <!-- <b>Overview of <span class="dnerf">Multi-Crit</span></b>  -->
          <i>Left</i>: Unlike prior works that assign a single overall preference label, <span class="dnerf">Multi-Crit</span> provides <span style="color: brown;">pluralistic, multi-criterion human judgments</span>, exposing <span style="color: brown;">conflicts between different evaluation criteria</span> within the same sample (e.g., Logic vs. No Hallucination, Reflection vs. Efficiency). <i>Right</i>: We introduce three complementary metrics to systematically assess LMM judges on their ability to follow pluralistic evaluation criteria, recognize preference trade-offs, and capture criterion-level conflicts.
        </p>
    </div>
    </div>

    <!-- Paper video. -->
    <!--/ Paper video. -->
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">

      <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="./static/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>

      <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="./static/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Animation</h2>

        <h3 class="title is-4">Interpolating states</h3>
        <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="./static/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/>

        <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>

      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Related Links</h2>

        <div class="content has-text-justified">
          <p>
            There's a lot of excellent work that was introduced around the same time as ours.
          </p>
          <p>
            <a href="https://arxiv.org/abs/2104.09125">Progressive Encoding for Neural Optimization</a> introduces an idea similar to our windowed position encoding for coarse-to-fine optimization.
          </p>
          <p>
            <a href="https://www.albertpumarola.com/research/D-NeRF/index.html">D-NeRF</a> and <a href="https://gvv.mpi-inf.mpg.de/projects/nonrigid_nerf/">NR-NeRF</a>
            both use deformation fields to model non-rigid scenes.
          </p>
          <p>
            Some works model videos with a NeRF by directly modulating the density, such as <a href="https://video-nerf.github.io/">Video-NeRF</a>, <a href="https://www.cs.cornell.edu/~zl548/NSFF/">NSFF</a>, and <a href="https://neural-3d-video.github.io/">DyNeRF</a>
          </p>
          <p>
            There are probably many more by the time you are reading this. Check out <a href="https://dellaert.github.io/NeRF/">Frank Dellart's survey on recent NeRF papers</a>, and <a href="https://github.com/yenchenlin/awesome-NeRF">Yen-Chen Lin's curated list of NeRF papers</a>.
          </p>
        </div>
      </div>
    </div>
     Concurrent Work.

  </div>
</section> -->


<section class="hero is-light" style="margin-top: 50px; margin-bottom: 10px; padding: 0;">
  <div class="hero-body" style="padding: 20px;">
  <h2 class="title is-1 has-text-centered is-light" style="padding:0"><span class="dnerf">Experimental Results</span></h2>
  </div>
</section>


<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3 has-text-centered">Results in Judging Open-ended Tasks</h2>
        <div class="content is-four-fifths">
          <img id="results-open-ended"
                src="./static/images/results/results-open-ended.png"
                alt="Shiba example"
                loading="lazy"
                style="object-fit:cover; margin-top: 5px; margin-bottom: 40px;" />
          </div>
      
      <div class="container">
        <div class="content is-four-fifths">
        <h2 class="title is-3 has-text-centered">Results in Judging Reasoning Tasks</h2>
        
          <img id="results-reasoning"
                src="./static/images/results/results-reasoning.png"
                alt="Shiba example"
                loading="lazy"
                style="object-fit:cover; margin-top: 5px; margin-bottom: 40px;" />
          </div>
      </div>
      <div class="content is-four-fifths">  
          <p>
            *The <b>best</b> and <u>second best</u> results are highlighted for each column in both tables.
          </p>

        </div>
      </div>
    </div>
  </div>
</section>





<!-- <section class="hero is-light"> -->

<section class="hero is-light" style="margin-top: 50px; margin-bottom: 10px; padding: 0;">
  <div class="hero-body" style="padding: 20px;">
  <h2 class="title is-1 has-text-centered is-light" style="padding:0"><span class="dnerf">Multi-Crit Benchmark</span></h2>
  </div>
</section>


<section class="hero">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
      <div class="column is-four-fifths">
      <h2 class="title is-3 has-text-centered">Overview</h2>

      <div class="content">
        <!-- <h3 class="title is-4">ðŸ’¥ Dataset Introduction</h3> -->
        <ul>
          <li>
            Multi-Crit consists of <b>425 multimodal prompts</b> accompanied by <b>1,425 criterion-level human preference annotations</b>.
            It covers two major scopes of multimodal judgment:
            <ul>
              <li>
                <i>Open-ended content generation</i> â€” where responses are free-form and traditional fixed metrics are limited.
              </li>
              <li>
                <i>Verifiable reasoning tasks</i> â€” where the judge model evaluates the quality of model-generated reasoning processes leading to objectively verifiable answers.
              </li>
            </ul>
          </li>
        </ul>
        <div id="criteria-carousel" class="carousel results-carousel" style="margin-bottom: 0rem; height: auto;">
          <div class="item" style="min-height: 400px;">
            
            <h4 class="title is-5 has-text-centered">Criteria for Judging Open-ended Tasks</h4>
            <img id="shiba"
               src="./static/images/criteria/criteria-open-ended.jpg"
               alt="Shiba example"
               loading="lazy"
               style="max-width: 100%; height: auto;" />

          
            
            <!-- <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <thead>
                <tr><th>Criteria</th><th>Brief description</th></tr>
              </thead>
              <tbody>
                <tr><td>Completeness and Coverage</td><td>Address the full scope of the task in the user's query, covering all major elements specified in the prompt as well as relevant visual aspects and contextual cues.</td></tr>
                <tr><td>Visual Grounding and Details</td><td>Reference observable elements in the image such as objects, spatial relationships, colors, or text, and bases its description or analysis on these details.</td></tr>
                <tr><td>Factuality / No Hallucination</td><td>Avoid visual or factual errors, ensuring all details and claims are presented in the image or reasonably supported by the prompt.</td></tr>
                <tr><td>Creativity and Expressiveness</td><td>Demonstrates imagination and originality when appropriate, or precise and knowledgeable articulation for analytical tasks, while remaining contextually appropriate.</td></tr>
                <tr><td>Clarity and Coherence</td><td>Communicates ideas clearly and logically, with fluent language, well-organized structure, and smooth flow of information.</td></tr>
              </tbody>
            </table> -->
          </div>
          <div class="item">
            <h4 class="title is-5 has-text-centered">Criteria for Judging Verifiable Reasoning Tasks</h4>
            <img id="item-reason1"
               src="./static/images/criteria/criteria-reasoning.jpg"
               alt="Shiba example"
               loading="lazy"
               style="max-width: 100%; height: auto;" />
            <!-- <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth">
              <thead>
                <tr><th>Criteria</th><th>Brief description</th></tr>
              </thead>
              <tbody>
                <tr><td>Visual Grounding</td><td>Reference important visual elementsâ€”such as objects, layout, or textâ€”and integrates them meaningfully into the reasoning.</td></tr>
                <tr><td>Logic Coherence and Consistency</td><td>Follow a clear, step-by-step logic without contradictions or unjustified leaps, and ensures the answer aligns with reasoning.</td></tr>
                <tr><td>Factuality / No Hallucination</td><td>Ensure accuracy of all claims and support them with the input, avoiding hallucinated visual details or factual errors.</td></tr>
                <tr><td>Reflection and Exploration</td><td>Demonstrate depth of reasoning through reflection and exploration of alternative interpretations, particularly in complex tasks.</td></tr>
                <tr><td>Conciseness and Efficiency</td><td>Remains concise and focused, matching the task complexity while avoiding redundancy or unnecessary over-analysis.</td></tr>
              </tbody>
            </table> -->
          </div>
        </div>


        

        <ul>
          <li>Three metrics are introduced to comprehensively evaluate whether LMM judges can follow pluralistic criteria:</li>
        </ul>
        <div style="display: flex; justify-content: center;">
        <table class="table is-bordered is-striped is-narrow is-hoverable is-fullwidth", style="margin-left: 20px; margin-right: 20px; width: 80%; ">
          <thead>
            <tr><th>Metric</th><th>Abbrev.</th><th>Description</th></tr>
          </thead>
          <tbody>
            <tr><td><b>Pluralistic Accuracy</b></td><td><code>PAcc</code></td><td>Check whether the judge gets <b>all criteria correct</b> for each evaluation instance.</td></tr>
            <tr><td><b>Trade-off Sensitivity</b></td><td><code>TOS</code></td><td>Assess whether the judge can <b>detect at least one criterion-level trade-off</b> between the two responses when humans disagreeâ€”i.e., predict at least one criterion pair with opposite preferences.</td></tr>
            <tr><td><b>Conflict Matching Rate</b></td><td><code>CMR</code></td><td>Measure whether the judge can <b>correctly resolve each conflicting criterion pair</b>, i.e., predicts both sides of every conflict in agreement with human labels.</td></tr>
          </tbody>
        </table>
        </div>


        
        <!-- <h3 class="title is-4">Construction Pipeline</h3> -->
        <div class="content" style="
          margin-top: 50px;
          padding: 20px;
          border-radius: 0px;
          box-shadow: 0 4px 15px rgba(0,0,0,0.12);
          background: white;
        ">
        <img src="./static/images/03_dataset_stats.png" alt="Data curation pipeline" style="margin-top: 30px auto; display: block; margin-bottom: 10px" />
        </div>
        <div class="content" style="
          margin-top: 50px;
          padding: 20px;
          border-radius: 0px;
          box-shadow: 0 4px 15px rgba(0,0,0,0.12);
          background: white;
        ">
        <img src="./static/images/02_pipeline.png" alt="Data curation pipeline" style="margin-top: 30px auto; display: block; margin-bottom: 10px" />
        <p class="has-text-centered" style="margin-top: 3px;">Benchmark construction pipeline.</p>
        </div>
        
      </div>


    </div>
  </div>
  </div>
  </div>
</section>





<section class="hero">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3 has-text-centered">Data Examples</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-open1">
          <img id="item-openend1"
               src="./static/images/example-data/ex-open1.png"
               alt="Shiba example"
               loading="lazy"
               style="max-width: 100%; height: auto;" />
        </div>
        <div class="item item-open2">
          <img id="item-openend2"
               src="./static/images/example-data/ex-open2.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover;" />
        </div>
        <div class="item item-open3">
          <img id="item-openend3"
               src="./static/images/example-data/ex-open3.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover;" />
        </div>
        <div class="item item-reason1">
          <img id="item-reason1"
               src="./static/images/example-data/ex-reason1.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover;" />
        </div>
        <div class="item item-reason2">
          <img id="item-reason2"
               src="./static/images/example-data/ex-reason2.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover;" />
        </div>
        <div class="item item-reason3">
          <img id="item-reason3"
               src="./static/images/example-data/ex-reason3.png"
               alt="Shiba example"
               loading="lazy"
               style="height:100%; width:100%; object-fit:cover;" />
        </div>
      </div>

    </div>
  </div>
</section>


<section class="section" id="BibTeX">
  <div class="container is-max-desktop content is-four-fifths">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{xiong2025multicritbenchmarkingmultimodaljudges,
      title={Multi-Crit: Benchmarking Multimodal Judges on Pluralistic Criteria-Following}, 
      author={Tianyi Xiong and Yi Ge and Ming Li and Zuolong Zhang and Pranav Kulkarni and Kaishen Wang and Qi He and Zeying Zhu and Chenxi Liu and Ruibo Chen and Tong Zheng and Yanshuo Chen and Xiyao Wang and Renrui Zhang and Wenhu Chen and Heng Huang},
      year={2025},
      eprint={2511.21662},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2511.21662}, 
}
</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <!-- <div class="content has-text-centered">
      <a class="icon-link"
         href="./static/videos/nerfies_paper.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div> -->
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is adapted from <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a>, under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
